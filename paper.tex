\documentclass[12pt]{turabian-researchpaper}
\usepackage[american]{babel}
\usepackage[babel]{csquotes}
\usepackage[notes,
    natbib,
    authordate,
    notetype=endonly,
    isbn=false,
    backend=biber
]{biblatex-chicago}  
\usepackage{epigraph}
\usepackage{quotetitle}
\usepackage{endnotes,ellipsis}

%\usepackage[left=2.25in,right=2.25in]{geometry}

\usepackage{setspace}
%\doublespacing
\spacing{2.15}

\addbibresource{\jobname.bib}

\title{Going Gray}
\subtitle{The Privacy Battle Between Law Enforcement and Individuals}
\author{Garrett Greenwood}
\date{Fall 2015}
\course{Dr Dow, ECS 3361}
\institution{The University of Texas at Dallas}
\titlequote{Without the ability to keep secrets, individuals lose the capacity to
distinguish themselves from others, to maintain independent lives,
to be complete and autonomous persons.... This does not mean
that a person actually has to keep secrets to be autonomous, just
that she must possess the ability to do so. The ability to keep
secrets implies the ability to disclose secrets selectively, and so the
capacity for selective disclosure at one's own discretion is important
to individual autonomy as well.}{Kim L. Scheppele\endnote{Kim L. Scheppele, Legal Secrets 302 (1988) (reference omitted).}}

\begin{document}

\maketitle

%\newgeometry{left=1.1,right=1.1in}

%\section{Introduction}
Government has always had a history of balancing the privacy interests of its citizens with the need for security or surveillance.
Often, law enforcement agencies must collect digital evidence from suspects in order to determine their guilt or innocence.
Recently, encryption has confounded these efforts by allowing anyone with a computer to communicate securely with little effort.
Law enforcement is worried about "going dark"\endnote{See \textcite{going-dark}.} and losing the ability to use evidence that they have legally obtained.
However, many of their proposed solutions, although technically possible, introduce a wide array of costs and vulnerabilities.

In order to protect the freedom of speech and privacy of information, strong encryption can be used to hide information from those without the proper credentials.
However, well-encrypted data is also impossible to use in legal cases, public defense, or surveillance and allows criminals to hide their digital actions.
To combat these activities, government agencies like NSA have been attempting to either limit the effectiveness of encryption methods or require methods for exceptional access to data.
This debate sparked in the '90s, when it was decided that encryption should be allowed with certain caveats, but it has resurfaced lately considering the amount of personal encrypted information that private companies hold.

This paper will cover the technical history of U.S. encryption standards since their introduction, focusing on the ways that the government is trying to maintain access to encrypted data.
Then, it will explore an important recent court case and proposal regarding the security of security of a private key and a new way to legally obtain evidence.

%\section{Technical History}
% DES
Publicly available encryption entered the spotlight in the early 1970s, with the U.S. Data Encryption Standard(DES).\endnote{See \textcite{metaphor1995} \S I.B.1.}
Built as a collaboration between the National Bureau of Standards, now the National Institute of Standards and Technology (NIST), and IBM, it was designed to replace the conflicting standards of the time.
The NSA was closely involved in its development, leading to concerns about its security and the possibility of a back door despite being certified as "free of any statistical or mathematical weaknesses".

DES was wildly successful and even became internationally used despite extensive export restrictions which treated it as a weapon, restricting U.S. based companies from selling DES-equipped products to foreigners.
Still, books containing the DES specifications could be printed and distributed freely and the standard quickly went global.\endnote{See \textcite{metaphor1995} \S I.C.1.c.i.}
Soon, it was the most used encryption standard.

DES is a symmetric encryption scheme, meaning that both parties can encrypt and decrypt plaintext with a shared key.
The key is 56 bits long, a sweet spot that made computation fast but could be brute-forced with reasonable investment.
For example, an investment of \$10 million in 1993 could produce a machine capable of cracking a DES key every twenty-one minutes\endnote{See \textcite{metaphor1995} \S I.B.2. and Appendix A.}
  and the Electronic Frontier Foundation spent \$250,000 on a custom machine in 1998 that cracked a key in twenty-two hours.\endnote{See \textcite{eff-des1998} p.1-14. EFF custom designed and built a machine with 1,856 custom chips, each capable of testing 60 million keys a second. 
  It can exhaust the entire keyspace(72,057,594,037,927,936 large) in a span of nine days, and will find the correct key in half that on average.}
Therefore, it would not be unreasonable for any country or wealthy individual to break DES reliably with enough investment.

% 1990s and key escrow
In the 1990s, NSA began to push a new standard for encryption that would give them access to encrypted information.
Called the Escrowed Encryption Standard (EES), it is designed so that users can communicate securely against decryption from everyone but the U.S. government.\endnote{See \textcite{metaphor1995} \S I.C. "Key escrow" refers to the recovery of the encryption key by the government.}
EES uses 80 bit keys and a stronger encryption method, making it at least $2^{14}$ times harder to brute force than DES.\endnote{Each bit added doubles the number of possible keys to choose from and therefore, the amount of time needed to guess the correct key. At the time of writing, 2,048 bit AES keys are considered secure and used by companies like Google.}
It is also built on the SKIPJACK algorithm, which was classified on release. Therefore, users of EES would need to rely on government-supplied implementations and escrow keys.

The main use of EES is in the Clipper Chip, a component that could be added to landline phones to enable encrypted communication.\endnote{See \textcite{metaphor1995} \S I.C.2.}
Each chip has a unique serial number and encryption key duplicatedand held by the government.
In order to safeguard these keys, each is split into half and given to different "escrow agents" who only release them if a lawful need is demonstrated.
These agents must protect these keys from theft, unlawful or fraudulent requests, and transmit them safely.\endnote{See \textcite{mit1997} \S 3.2.2.}

To participate in a Clipper-encrypted phone call, users must press a red button to enable the security feature. At this point, two more keys come into play.
The two phones coordinate a session key unique to that phone call, encrypt it using their preprogrammed chip keys, append their device IDs, encrypt it again using a government master key, and finally broadcast the result over the line.
Law enforcement agencies who have a record of this call can then use the master key to uncover the IDs of each phone in the conversation.
Once they obtain the corresponding key from the escrow agents, they can decrypt again to get the underlying session key which opens up the entire message.\endnote{See \textcite{metaphor1995} \S I.C.2.a.}

All of this complexity creates a secure environment only if several assumptions hold true.
The governmental master key may not fall into the wrong hands. Although the key will only exist in hardware circulated among law enforcement agencies, it may still be stolen or used nefariously.\endnote{See \textcite{metaphor1995} note 194.}
The escrow agents must only hand over keys in the case of lawful requests, and keep them safe otherwise.\endnote{See \textcite{mit1997} \S 3.2.1, \S 3.2.3. and \textcite{metaphor1995} \S I.C.2.b.}
The phones communicating must implement a secure method for choosing a session key. This step isn't handled by the Clipper Chip and must be implemented by each manufacturer.\endnote{See \textcite{metaphor1995} \S I.C.2.a and note 189.}
Finally, each implementation of these encryption methods must not have mistakes. Like the recent Heartbleed vulnerability, a small error may lead to the exploitation of the entire system.
If any of these goes wrong, the integrity of the entire system and the promised security is lost.

All of these issues and more were brought up by a group of scholars and cryptoanalysts in 1997\endnote{\textcite{mit1997} concluded that the system would "require significant sacrifices in security and convenience and substantially increased costs to all users of encryption.
Furthermore, building the secure infrastructure of the breathtaking scale and complexity that would be required for such a scheme is beyond the experience and current competency of the field, and may well introduce ultimately unacceptable risks and costs."}.
Their article on the technical hurdles of a key escrow system was instrumental in the public debate and the Clipper Chip was eventually abandoned\endnote{See \textcite{mit2015} p.1}.

% 2015 revisit
In the meantime, innovation on the Internet has flourished in an environment supported by open encryption standards.
Systems like Twitter and Facebook would likely not exist if there was a requirement for built in key escrow.
Even still, law enforcement's fears about "going dark" and being unable to collect important evidence came untrue and in fact, they have "much better and more effective surveillance capabilities now than [they] did then"\endnote{See textcite{mit2015} p.2}.

Today, encryption is at the heart of the Internet.
Society has become more dependent on these systems which are under constant attack, increasing the importance of encryption since it entered the public sphere forty years ago.
We have also learned more about how to build strong cryptosystems, although their difficulty is still mainly in the implementation.
Encryption standards are also no longer under export restrictions and the Advanced Encryption Standard (AES) is now used around the world, much like DES was.\endnote{See \textcite{mit2015} \S 1.3.}
Otherwise, the encryption environment today is very similar to when the escrow debate came up in the 1990s.

Modern cryptography systems are asymmetric and rely on seperate keys for encryption (public key) and decryption (private key).
This seperation is vital to the security of the Internet.
It is common for a website to give out their public key, allowing others to send them messages, verify their identity, and protect against forgery.
Likewise, if a website's private key got leaked, all of their messages could be understood and others could pose as them and forge messages.
Therefore, it is important for a website to protect its private key.

The context of the debate has also switched from law enforcement requesting "key escrow services" to "exceptional access methods".
The key difference is that exceptional access is much more broad and encompasses key escrow.
Exceptional access is the ability for law enforcement agencies to obtain the plain text for any encrypted message that they can obtain through legal means.
This would require all implementors of encryption to be able to decrypt user data transparently and at will, which poses two issues with modern communication security practices.\endnote{See \textcite{mit2015} \S 2.1.}

The first issue lies in the practice of \textit{forward secrecy}.
Similar to the Clipper Chip discussed earlier, each session has its own symmetric session key shared between both parties.
It is quickly becoming standard standard practive to delete these session keys after each transaction.
In this model, the system is more safe against attacks because an attacker will only be able to compromise ongoing sessions.
Otherwise, a single infiltration could lead to the compromise of the entire history of encrypted information.\endnote{See \textcite{mit2015} \S 2.1.}

As a result, the system has no way of reading messages sent in the past, which is directly incompatible with the needs of an exceptional access system.

The second issue is that the current best practice involves using \textit{authenticated encryption} to verify both the identity of the other party and that the message hasn't be tampered with.
Therefore, this method can provide both authentication and confidentiality.
A private key is used to generate signatures while the public key can verify the integrity of the message and sender.
Implementing key escrow in order to read messages would therefore compromise the private key, giving the ability to forge messages and ruining the integrity of the system.\endnote{See \textcite{mit2015} \S 2.1.}

Both of these modern practices are reduced in effectiveness by the need to provide exceptional access.
Additionally, the nature of today's large app economy would make it nearly impossible to perfectly implement exceptional access.
If one app implemented key escrow, its users who are concerned about the security implications of a more complicated system could simple move to another system.

However, that just covers the technical aspects to the ongoing debate on exceptional access methods.
There are still many legal and ethical facets to explore.

% Lavabit case
In summer 2013, Edward Snowden announced his identity as the former CIA employee who had leaked classified information,
and released his email as \textit{edsnowden@lavabit.com}.
Lavabit was a new company built on the idea of providing best-practice encrypted email services(including forward secrecy) and had over 400,000 users at its peak.
th, and the next day, Lavabit received a court order to provide metadata\endnote{"Metadata refers to information about the message, but not the message itself. It includes login date, times, and IP addresses, as well as email headers. See \textcite{lavabit-opinion} p.12} on an unnamed user, likely Snowden.\endnote{There is no conclusive evidence that Edward Snowden was the target of the search, but "the timing and circumstances suggest" it, according to Kevin Paulson of Wired.}

In response, Lavabit refused to comply because the user had enabled their encryption services and "[they] did not want to defeat their own system."\endnote{See \textcite{lavabit-opinion} p.10}
Eventually, Lavabit agreed to collect and turn over the requested data.
However, Levison, the owner of Lavabit, would only do so if he implemented the listener himself and received payment for his development time.
The government denied this proposal because they wanted real-time data and they would not be able to verify the integrity of the data provided.

The government then received a seizure warrant to obtain "[a]ll information necessary to decrypt communications sent to and from [the target's] Lavabit email account..., including encryption and SSL keys."\endnote{See \textcite{lavabit-opinion} p.13}
Lavabit later argued that this request for their private key was unreasonable because, if a legal precedent, would threaten the security of the Internet, and that it violated the Fourth amendment.\endnote{See \textcite{lavabit-brief}.}

Modern security measues on the internet are based greatly on the ability of a website to keep its private key secret.
The loss of a private key would allow an attacker to steal user information, modify their servers, and forge requests from the server.
Furthermore, companies often enter a contract with Certificate Authorities, whose purpose is to verify the identity of the server by vouching for their public key.
The loss of a private key for any reason is often grounds for the removal of this voucher, branding the site as insecure and compromised.\endnote{See \textcite{lavabit-brief} p.16-18}

Next, the Fourth amendment protects people from unreasonable searches and seizures.
Obtaining the private key would not only give the government the ability to view the target's records, but all of Lavabit's 400,000 users as well.
additionally, search and seizure warrants must "be as limited as possible... [to ensure] that nothing is left to the discretion of the officer executing the warrant"\endnote{See \textcite{lavabit-brief} p.24 and \textit{Coolidge}, 403 U.S. at 467.}
Because the request is a so-called "general warrant" it would not be allowed.

Lavabit's appeal(which was based on these two principles) was rejected because they were not raised in a lower court.
The court did not decide conclusively whether the government can compel an email provider to disclose their encryption keys.
Lavabit conceded and yielded their private key to the government and proceded to shut down since it could no longer securely accomplish its goals.

% "Going bright"
Still one more issue has come up lately since the topic's refresh. 
In response to the Congressional hearing that revitalized the debate, a new proposal suggested a method of wiretapping without needing to weaken the secure infrastructure.\endnote{\textcite{going-bright}}
This approach involves leaving the underlying software as it is and instead exploits hidden bugs.
These so-called \textit{0-day vulnerabilities} (named so because bugs are discovered on day 0 and worked on later) are often subtle but can have great effects on the security of the system.
For example, the Heartbleed bug allowed for private keys used in certificates to be cracked with minimal effort.
From these keys, an attacker can access all of the data in the website's databases, including user communications.\endnote{See \textcite{heartbleed}}

A recent study found that these 0-day vulnerabilities last an average of 312 days between first use and their public disclosure.\endnote{See \textcite{going-bright} p.69}
During this time, the closed knowledge of the bug is extremely valuable since it can be used for surveillance and evidence gathering.
As a result, these bugs have become commodoties that are being sold both in commercial and underground markets.

The FBI can spend resources either discovering 0-days on their own or purchasing them on the market.
Once obtained, they can develop an exploit tool that compromises a vulnerable target using the bug.
These tools would be extensively tested to ensure that they don't deal any collateral damage, then will be distributed to law enforcement and used where legally appropriate.

This practice would open up its own class of questions if it were to be publicly adopted.
Should the government exploit these bugs silently, or report them and improve the software base?
Should the government discover these bugs with their own research teams, or purchase them commercially?
If they are purchased commercially, where does the government draw the line when buying from questionable sources?

The last question at least has an analog in current public policy.
The use of paid informers to uncover a criminal organization similarly serves to support one who's activities are against good public policy.
Also, the law enforcement officers performing the exploit will still be held to wiretapping laws, such as minimization.\endnote{See \textcite{going-bright} p.70. Minimization ensures that the wiretapping only captures the subject and only during their criminal activities.}

The battle between law enforcement agencies seeking ways to decrypt the information they have the legal right to obtain and the progress of the open Internet which is built on strong encryption is ongoing.
Several key escrow and exceptional access methods have been proposed, but all are too complex and insecure to be successful.
Therefore, law enforcement must find other ways to decrypt evidence.

Although they have done this already in the form of inelegant legal procedures, the privacy of many other individuals has been compromised.
I suggest that the government begin exploring the policy issues inherent in exploiting hidden bugs in order to decrypt information.
This path leads (eventually) to a more secure Internet through the active pursuit of bugs and does not stand in the way of the Internet's progress.

\pagebreak
\theendnotes
\pagebreak
\printbibliography
\end{document}
